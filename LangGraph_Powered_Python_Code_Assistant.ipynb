{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN57R+Ya9wDtKFwKc3bDWQ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohamedBole/LangGraph-Powered-Python-Code-Assistant/blob/main/LangGraph_Powered_Python_Code_Assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#install Dependance"
      ],
      "metadata": {
        "id": "2LUQWqsk2SEo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "NMUgu2Md2PY8",
        "outputId": "c3439f70-29aa-4853-8598-bdb37d2a6e7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.9-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.72)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.3-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.0 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.8)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.7.14)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.6.3-py3-none-any.whl (152 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.5/152.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.1.9-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.3-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, ormsgpack, langgraph-sdk, langgraph-checkpoint, google-ai-generativelanguage, langgraph-prebuilt, langchain-google-genai, langgraph\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.18 langchain-google-genai-2.1.9 langgraph-0.6.3 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.3 langgraph-sdk-0.2.0 ormsgpack-1.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "4cd2c6f659684f9faf190772bc549635"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install langgraph langchain langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import TypedDict, List, Union\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import langchain\n",
        "import langchain_google_genai\n",
        "from langchain_core.messages import BaseMessage # The foundational class for all message types in LangGraph\n",
        "from langchain_core.messages import SystemMessage # Message for providing instructions to the LLM\n",
        "from langgraph.graph.message import add_messages"
      ],
      "metadata": {
        "id": "KKNpd_F120s9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Set the API key as an environment variable\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# 2. Instantiate the LLM without explicitly passing the key\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    temperature=0\n",
        ")"
      ],
      "metadata": {
        "id": "QkdtAlFi4ZUv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# State Schema"
      ],
      "metadata": {
        "id": "ueB2cs_v3elM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "    messages : List[Union[HumanMessage, AIMessage]]\n",
        "    task : str"
      ],
      "metadata": {
        "id": "uY_NpxbK3IrA"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Explain Node"
      ],
      "metadata": {
        "id": "o8LqXEPIHx8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def explain(state:AgentState) -> AgentState:\n",
        "    system_prompt = SystemMessage(content=\n",
        "        \"You are my AI Python code  assistant, please explian my code provided to you.\"\n",
        "    )\n",
        "    response = llm.invoke([system_prompt] + state[\"messages\"])\n",
        "    print(f\"\\nAI Explaination:: {response.content}\")\n",
        "    return {\"messages\": [response]}"
      ],
      "metadata": {
        "id": "l5NXCnZAH0aP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generate Node"
      ],
      "metadata": {
        "id": "l2n4q6h5K1ZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(state:AgentState) -> AgentState:\n",
        "    system_prompt = SystemMessage(content=\n",
        "        \"You are my AI Python code  assistant, please generate this code for me.\"\n",
        "    )\n",
        "    response = llm.invoke([system_prompt] + state[\"messages\"])\n",
        "    print(f\"\\nAI Generating Code:: {response.content}\")\n",
        "    return {\"messages\": [response]}"
      ],
      "metadata": {
        "id": "0SFI3kvuLHBy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conditional Node"
      ],
      "metadata": {
        "id": "3vGjP2ZyL-Rd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Intent Classification Node\n",
        "def classify_intent(state: AgentState) -> AgentState:\n",
        "    user_input = state[\"messages\"][-1].content if state[\"messages\"] else \"\"\n",
        "\n",
        "    # Create a prompt for the LLM to classify intent\n",
        "    prompt = f\"\"\"\n",
        "    Classify the intent of the following user input into one of these categories: 'explain' or 'generate'.\n",
        "\n",
        "    Guidelines:\n",
        "    - If the user asks to explain, understand, describe, or analyze code, return 'explain'\n",
        "    - If the user asks to write, create, build, or generate code, return 'generate'\n",
        "\n",
        "    User input: {user_input}\n",
        "    Return only the intent as a single word (either 'explain' or 'generate').\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = llm.invoke(prompt)\n",
        "        intent = response.content.strip().lower()\n",
        "        if intent not in [\"explain\", \"generate\"]:\n",
        "            intent = \"explain\"  # Default to explain if the response is invalid\n",
        "    except Exception as e:\n",
        "        print(f\"Error in intent classification: {e}\")\n",
        "        intent = \"explain\"  # Fallback to explain on error\n",
        "\n",
        "    print(f\"Classified intent: {intent}\")\n",
        "    return {\"task\": intent}"
      ],
      "metadata": {
        "id": "NmcPcP2pMC8X"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Router function for conditional edges\n",
        "def router(state: AgentState) -> str:\n",
        "    \"\"\"Route to the appropriate node based on task.\"\"\"\n",
        "    return state[\"task\"]"
      ],
      "metadata": {
        "id": "LxO_PAYPa9u_"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Graph"
      ],
      "metadata": {
        "id": "-DmSmBoPHZ0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the graph\n",
        "graph = StateGraph(AgentState)\n",
        "\n",
        "# Add nodes\n",
        "graph.add_node(\"classify_intent\", classify_intent)\n",
        "graph.add_node(\"explain\", explain)\n",
        "graph.add_node(\"generate\", generate)\n",
        "\n",
        "# Define edges\n",
        "graph.add_edge(START, \"classify_intent\")\n",
        "graph.add_conditional_edges(\n",
        "    \"classify_intent\",\n",
        "    router,\n",
        "    {\n",
        "        \"explain\": \"explain\",\n",
        "        \"generate\": \"generate\",\n",
        "    }\n",
        ")\n",
        "graph.add_edge(\"explain\", END)\n",
        "graph.add_edge(\"generate\", END)\n",
        "\n",
        "# Compile the graph\n",
        "agent = graph.compile()"
      ],
      "metadata": {
        "id": "prgIj3GzHUbY"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "display(Image(agent.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "dZoqlnL6GT2p",
        "outputId": "e1ec0298-1cdf-41d7-ab2b-b1502e03e59b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chat"
      ],
      "metadata": {
        "id": "YNpA5v5lvyfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chat Interface with Memory\n",
        "class ChatSession:\n",
        "    def __init__(self, agent):\n",
        "        self.agent = agent\n",
        "        self.conversation_history = []\n",
        "\n",
        "    def add_to_history(self, message):\n",
        "        \"\"\"Add message to conversation history\"\"\"\n",
        "        self.conversation_history.append(message)\n",
        "        # Keep only last 10 messages to avoid token limits\n",
        "        if len(self.conversation_history) > 10:\n",
        "            self.conversation_history = self.conversation_history[-10:]\n",
        "\n",
        "    def get_response(self, user_input):\n",
        "        \"\"\"Get response from the agent with conversation context\"\"\"\n",
        "        # Create current message\n",
        "        current_message = HumanMessage(content=user_input)\n",
        "\n",
        "        # Combine history with current message\n",
        "        all_messages = self.conversation_history + [current_message]\n",
        "\n",
        "        # Get response from agent\n",
        "        response = self.agent.invoke({\n",
        "            \"messages\": all_messages,\n",
        "            \"task\": \"\"\n",
        "        })\n",
        "\n",
        "        # Add both user input and AI response to history\n",
        "        self.add_to_history(current_message)\n",
        "        if response.get(\"messages\"):\n",
        "            self.add_to_history(response[\"messages\"][-1])\n",
        "\n",
        "        return response"
      ],
      "metadata": {
        "id": "iOnzzIWlv1Uk"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def start_chat():\n",
        "    \"\"\"Start the interactive chat session\"\"\"\n",
        "    print(\"🤖 Python Code Assistant\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"Hello! I'm your Python code assistant.\")\n",
        "    print(\"I can help you:\")\n",
        "    print(\"  • Explain Python code\")\n",
        "    print(\"  • Generate Python code\")\n",
        "    print(\"  • Answer programming questions\")\n",
        "    print(\"\\nType 'exit' to quit the chat.\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Initialize chat session\n",
        "    chat_session = ChatSession(agent)\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            # Get user input\n",
        "            user_input = input(\"\\n👤 You: \").strip()\n",
        "\n",
        "            # Check for exit command\n",
        "            if user_input.lower() in ['exit', 'quit', 'bye', 'goodbye']:\n",
        "                print(\"\\n🤖 Assistant: Goodbye! Happy coding! 👋\")\n",
        "                break\n",
        "\n",
        "            # Skip empty inputs\n",
        "            if not user_input:\n",
        "                print(\"Please enter a message or type 'exit' to quit.\")\n",
        "                continue\n",
        "\n",
        "            # Get response from agent\n",
        "            print(\"\\n🤖 Assistant: \", end=\"\")\n",
        "            response = chat_session.get_response(user_input)\n",
        "\n",
        "            # The response is already printed by the node functions\n",
        "            # Just add a separator for better readability\n",
        "            print(\"\\n\" + \"-\" * 50)\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\n🤖 Assistant: Chat interrupted. Goodbye! 👋\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"\\n❌ Error: {e}\")\n",
        "            print(\"Please try again or type 'exit' to quit.\")"
      ],
      "metadata": {
        "id": "NdJbPlbXwCHv"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lT0iX8l9wZ3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run Agent"
      ],
      "metadata": {
        "id": "eVp31zjPHUyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Uncomment one of these options:\n",
        "\n",
        "    # Option 1: Start interactive chat\n",
        "    start_chat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mkc6KdBXlhAS",
        "outputId": "09000db1-45a8-4bec-9e15-6891de4ccee5"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤖 Python Code Assistant\n",
            "==================================================\n",
            "Hello! I'm your Python code assistant.\n",
            "I can help you:\n",
            "  • Explain Python code\n",
            "  • Generate Python code\n",
            "  • Answer programming questions\n",
            "\n",
            "Type 'exit' to quit the chat.\n",
            "==================================================\n",
            "\n",
            "👤 You: hello, can you explain this code for me 'display(Image(agent.get_graph().draw_mermaid_png()))'\n",
            "\n",
            "🤖 Assistant: Classified intent: explain\n",
            "\n",
            "AI Explaination:: That code snippet displays a Mermaid diagram generated from a graph within a Python environment that likely uses Jupyter Notebooks or a similar interactive computing environment. Let's break it down:\n",
            "\n",
            "* **`agent.get_graph()`:** This part assumes you have an object named `agent` which has a method called `get_graph()`. This method returns a graph object.  The nature of this graph object depends on the library or framework you're using. It's likely a graph representation used in a specific domain, such as a knowledge graph, a dependency graph, or a workflow graph.\n",
            "\n",
            "* **`.draw_mermaid_png()`:** This is a method called on the graph object.  It suggests that the graph object has a capability to render itself as a PNG image using the Mermaid syntax. Mermaid is a popular markdown-like language for creating diagrams and flowcharts.  This method likely takes the graph's structure and translates it into Mermaid code, then renders that code into a PNG image.\n",
            "\n",
            "* **`Image(...)`:** This is a function (likely from a library like `IPython.display`) that takes an image file path or binary data and creates an `Image` object suitable for display within a Jupyter Notebook or similar interactive environment.  It's taking the PNG data generated by `.draw_mermaid_png()` and wrapping it into a displayable object.\n",
            "\n",
            "* **`display(...)`:** This is a function (again, likely from `IPython.display`) that renders the `Image` object within the notebook.  It shows the generated PNG image of the Mermaid diagram in the output cell.\n",
            "\n",
            "\n",
            "**In summary:** The code fetches a graph from an `agent` object, converts it into a Mermaid diagram, renders that diagram as a PNG image, and then displays that image in the output.  The entire process relies on having a suitable library installed that provides the `Image` and `display` functions, and an `agent` object with the appropriate methods for graph manipulation and rendering.  The specific library used will determine the exact behavior and capabilities.  Libraries like `ipython`, `graphviz`, and potentially custom libraries are possibilities.\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "👤 You: Can you generate a function to calculate fibonacci numbers?\n",
            "\n",
            "🤖 Assistant: Classified intent: generate\n",
            "\n",
            "AI Generating Code:: Here are a few functions to calculate Fibonacci numbers, each with different approaches and trade-offs:\n",
            "\n",
            "**1. Recursive Approach (Simple, but inefficient for large numbers):**\n",
            "\n",
            "```python\n",
            "def fibonacci_recursive(n):\n",
            "  \"\"\"\n",
            "  Calculates the nth Fibonacci number recursively.\n",
            "\n",
            "  Args:\n",
            "    n: The index of the desired Fibonacci number (starting from 0).\n",
            "\n",
            "  Returns:\n",
            "    The nth Fibonacci number.\n",
            "  \"\"\"\n",
            "  if n <= 1:\n",
            "    return n\n",
            "  else:\n",
            "    return fibonacci_recursive(n-1) + fibonacci_recursive(n-2)\n",
            "\n",
            "```\n",
            "\n",
            "This is the most straightforward implementation, directly mirroring the mathematical definition. However, it's extremely inefficient for larger values of `n` due to repeated calculations.\n",
            "\n",
            "\n",
            "**2. Iterative Approach (Efficient):**\n",
            "\n",
            "```python\n",
            "def fibonacci_iterative(n):\n",
            "  \"\"\"\n",
            "  Calculates the nth Fibonacci number iteratively.\n",
            "\n",
            "  Args:\n",
            "    n: The index of the desired Fibonacci number (starting from 0).\n",
            "\n",
            "  Returns:\n",
            "    The nth Fibonacci number.\n",
            "  \"\"\"\n",
            "  a, b = 0, 1\n",
            "  for _ in range(n):\n",
            "    a, b = b, a + b\n",
            "  return a\n",
            "\n",
            "```\n",
            "\n",
            "This iterative approach is much more efficient, avoiding redundant calculations.  It's generally the preferred method for calculating Fibonacci numbers.\n",
            "\n",
            "\n",
            "**3. Dynamic Programming Approach (Efficient, avoids recalculation):**\n",
            "\n",
            "```python\n",
            "def fibonacci_dynamic(n):\n",
            "  \"\"\"\n",
            "  Calculates the nth Fibonacci number using dynamic programming.\n",
            "\n",
            "  Args:\n",
            "    n: The index of the desired Fibonacci number (starting from 0).\n",
            "\n",
            "  Returns:\n",
            "    The nth Fibonacci number.\n",
            "  \"\"\"\n",
            "  fib_numbers = [0, 1]\n",
            "  if n <= 1:\n",
            "    return fib_numbers[n]\n",
            "  else:\n",
            "    for i in range(2, n + 1):\n",
            "      next_fib = fib_numbers[i - 1] + fib_numbers[i - 2]\n",
            "      fib_numbers.append(next_fib)\n",
            "    return fib_numbers[n]\n",
            "\n",
            "```\n",
            "\n",
            "Dynamic programming stores previously calculated Fibonacci numbers to avoid recalculating them.  This is also efficient, especially if you need multiple Fibonacci numbers.\n",
            "\n",
            "\n",
            "**4. Using a Generator (Memory Efficient for large sequences):**\n",
            "\n",
            "```python\n",
            "def fibonacci_generator(n):\n",
            "  \"\"\"\n",
            "  Generates Fibonacci numbers up to n using a generator.\n",
            "\n",
            "  Args:\n",
            "    n: The upper limit for the Fibonacci sequence.\n",
            "\n",
            "  Yields:\n",
            "    The next Fibonacci number in the sequence.\n",
            "  \"\"\"\n",
            "  a, b = 0, 1\n",
            "  for _ in range(n):\n",
            "    yield a\n",
            "    a, b = b, a + b\n",
            "\n",
            "# Example usage:\n",
            "for i in fibonacci_generator(10):\n",
            "    print(i)\n",
            "\n",
            "```\n",
            "\n",
            "This approach is memory-efficient if you need to generate a very long sequence of Fibonacci numbers, as it doesn't store the entire sequence in memory at once.\n",
            "\n",
            "\n",
            "Choose the method that best suits your needs.  For most cases, the iterative approach (`fibonacci_iterative`) provides a good balance of simplicity and efficiency.  For extremely large `n`, the generator approach might be necessary to avoid memory issues.  The recursive approach is primarily for illustrative purposes to show the mathematical definition.\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "👤 You: exit\n",
            "\n",
            "🤖 Assistant: Goodbye! Happy coding! 👋\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_JpBeRAnwcbH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}